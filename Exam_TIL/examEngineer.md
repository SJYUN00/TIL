# 머신러닝

1. 파이선 주요 패키지

   1. 머신러닝 패키지 : 사이킷 런

   2. 행렬/선형대수/통계 패키지 : 넘파이

   3. 데이터 핸들링 : 판다스

   4. 데이터 시각화 : 맷플롯립

      

2. 머신러닝 Cycle 4가지 

   

3. 머신러닝 분류

   1. 지도학습 : 분류, 회귀, 시각/음성감지/인지, 테스트분석/NLP

   2. 비지도학습 : 클러스터링(군집화), 차원축소, 추천시스템

   3. 반지도학습

   4. 강화학습

      

4. 사이킷런

   1. 파이썬 기반의 머신러닝을 위한 개발 라이브러리 제공

   2. 쉽고 파이선스러운 API 제공

   3. 다양한 알고리즘과 편리한 프레임워크 및 API 제공

   4. 검증되고 성숙한 라이브러리

   5. 보통 테스트 데이터 80%, 학습데이터 20% 할당  // hold-out 방식

   6. ML 모델학습 : fit()  / 학습된 모델 예측 : predict() 메서드 제공

   7. 문자열 값을 입력값으로 허용 안함, 인코딩해서 숫자 형으로 변환해야함

      

5. k-fold(교차검증)

   1. 자료 수가 충분하지 않는 경우에는 훈련 데이터에서 너무 많은 양의 데이터를 검증 또는 평가 데이터에 뺏기지 않도록 교차 검증 기법을 사용

   2. 자료를 균등하게 k개의 그룹으로 분할

   3. 각 j에 대해 j번째 그룹을 제외한 나머지 k-1개 그룹의 자료를 이용하여 모델에 적합

   4. j번째 그룹의 자료에 적합된 모델을 적용한 뒤 예측 오차를 구함

   5. j=1, ..., k에 대하여 위의 과정을 반복한 뒤, k 개의 예측 오차의 평균을 구함

   6. 예측 오차의 평균값을 기준으로, 모델의 검증 도는 평가를 수행

      

6. 앙상블 

   1. 여러개의 분류기를 생성하고 그 예측을 결합함으로써 보다 정확한 최종 예측을 도출하는 기법

   2. 보팅

      1. 여러개의 분류기가 투표를 통해 최종 예측 결과를 결정(단, 서로다른 알고리즘을 가진 분류기를 결합)

   3. 배깅

      1. 각각의 분류기가 모두 같은 유형의 알고리즘 기반, 데이터 샘플링을 서로 다르게 가져가면서 수행
      2. 랜텀 포레스트
         1. 여러 개의 결정 트리 분류기가 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링해 개별적으로 학습을 수행한 뒤 최종적으로 모든 분류기가 보팅을 통해 예측을 결정하게 됨

   4. 부스팅

      1. 여러개의 분류기가 순차적으로 학습하되 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서는 올바르게 예측할 수 있도록 다음 분류기에게는 가중치를 부여

      2. GBM 

         1. 여러개의 약한 합습기를 순차적으로 학습-예측하면서 잘못예측한 데이터에 가중치 부여를 통해 오류를 개선하는 방식

      3. XGBoost 

         1. GBM의 단점인 느린수행시간 및 과적합 규제 부대 등의 문제를 해결한 방법

            

7. 로지스틱 회귀 

   1. 시그모이드 함수 최적선을 찾고 이 시그모이드 함수의 반환 값을 확률로 간주해 확률에 따라 분류를 결정
   2. 0과 1의 값으로 예측

8. K-Means Clustering

   1. 2개의 군집 중심점을 설정
   2. 각 데이터는 가장 가까운 중심점에 소속
   3. 중심점에 할당된 데이터들의 평균 중심으로 중심점 이동
   4. 각 데이터는 이동된 중심점 기준으로 가장 가까운 중심점에 소속
   5. 다시 중심점에 할당된 데이터들의 평균 중심으로 중심점 이동
   6. 장점 
      1. 가장 많이 활용
      2. 쉽고 간결
   7. 단점
      1. 속성 개수가 많을 경우 군집화 정확도가 떨어짐
      2. 반복을 수행하는데 반복횟수가 많을 경우 수행시간이 느려짐
      3. 몇 개의 군집을 선택해야 할지 가이드가 어려움

9. 의사결정 트리

   1. 데이터에 있는 규칙을 학습을 통해 자동적으로 찾아내 트리 기반의 분류규칙을 만드는 것(if/else)

   2. 과적합으로 알고리즘 성능이 떨어질 수 있음

   3. 트리의 크기를 사전에 제한하는 튜닝 필요

      

10. Bag of words

    1. 문서가 가지는 모든 단어를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도 값을 부여해 피처값을 추출하는 것

# DataBase

1. SQL 인덱스 : 추가적인 쓰기 작업과 저장 공간을 활용하여 데이터베이스 테이블의 검색 속도르 향상시키기 위한 자료구조, 무결성을 위해도 사용됨

   

2. DDL : create, alter, drop, truncate

   

3. DML : select, insert, delete, update

   

4. DCL : grant, revoke, commit, rollback

   

5. Null : 어떤값이 들어올지 모르는 값

   

6. DB와 엑셀의 차이  : db는 여러사람이 이용할 수 있도록 하는 것

   

7. ICBM : IoT, Cloud, Bigdata, Mobile

   

8. 트랜잭션 : 데이터베이스의 상태를 변화시키기 위해 수행하는 작업의 단위 / 4가지 특정(ACID)

   1. 원자성, 일관성, 적합성, 지속성

   2. 위 4가지 속성을 모두 만족하면 RDBMS

      

9. 옵티마이저 : 사용자가 질의한 SQL문에 대해 최적의 실행 방법을 결정하는 역할 수행, 이러한 최적의 실행방법을 실행계획(execution plan)이라 함

   1. rule base(RBO) : 미리 정해진 규칙에 의해 실행계획을 결정, 무조건 정해진 규칙을 따르고 인덱스가 있으면 무조건 인덱스를 타기 때문에 인덱스 효율이 없는 경우도 있음

   2. cost base(CBO) : SQL을 수행할때 소요될 비용을 예측하고 그 값을 기준으로 실행계획을 결정, 무조건 정해진 규칙에 따르기보다 통계에 근거하기에 RBO보다 최적화된 판단이 나올 수 있다

      

10. 탐색방법

    - full table scan : 테이블 전체 읽기

    - index research : 인덱스를 기준으로 탐색, 적은 시간에 탐색가능(optimizer가 개입됨)

      

11. 카디널리디 (튜플의 개수)

    1. 인덱스 설정시 카디널리티가 높은 것을 컬럼으로 설정하는 게 좋음 : 카디널리디가 높다 - 중복도가 낮다



# 스파크

1. 스파크를 사용하는 이유 및 단점
   1. 필요한 데이터를 매번 디스크에서 가져오는 대신 메모리 캐시로 저장하는 인-메모리 실행 모델임, 맵리듀스보다 최대 100배 빠르게 가능
   2. 약간의 오버헤드가 발생하기에 단일 머신으로도 충분히 처리할 수 있는 소규모 데이터를 다루는 것에는 부적합
2. RDD, RDD 구성 요소 
   1. RDD 성질 : 불변성, 복원성, 분산
   2. 변환연산자 : RDD 데이터를 조작해 새로운 RDD 생성
   3. 행동연산자 : 연산자를 호출한 프로그램으로 계산 결과를 반환
3. MLlib : 머신러닝 라이브러리로 로지스틱회귀, 나이브베이즈 분류, 서포트 벡터머신, 의사결정트리, 랜덤포레스트, 선형회귀, K-means Clustering 지원
4. 스파크 스트리밍 : 다양한 데이터 소스에서 유입되는 실시간 스트리밍 데이터를 처리하는 프레임 워크
5. SQL : 스파크와 하이브SQL이 지원하는 SQL을 사용해 대규모 분산 정형 데이터를 다룰 수 있는 기능 제공
6. Graphx : 그래프 RDD형태의 그래프 구조를 만들수 있는 기능을 제공

# 기타

- 파이선이 빠른 이유 : 메모리 기반 저장